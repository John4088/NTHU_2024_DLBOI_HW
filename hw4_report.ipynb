{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John4088/NTHU_2024_DLBOI_HW/blob/main/hw4_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DMsCjqwDH0l",
        "outputId": "7342a2fc-8020-4ce6-c721-ca0237a064c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "ResNet50 架構:\n",
            " ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "\n",
            "VGG16 架構:\n",
            " VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "ResNet50 選擇理由：\n",
            "architecture: ResNet50 使用殘差塊結構，適合處理更深的網路，並可以降低梯度消失的風險。\n",
            "pretrained_performance: 在 ImageNet 上有高準確度，適合複雜的特徵提取。\n",
            "transfer_learning_potential: 因為架構較深且適應性強，適合遷移學習中的細微分類任務。\n",
            "\n",
            "VGG16 選擇理由：\n",
            "architecture: VGG16 使用多層卷積層，結構相對簡單，易於理解和修改。\n",
            "pretrained_performance: 在 ImageNet 上也具備良好準確度，尤其在圖片分類方面。\n",
            "transfer_learning_potential: 穩定適用於遷移學習，適合計算時間較短的任務，但可能需要調整層數以適應新任務。\n",
            "\n",
            "推理時間測試（毫秒）：\n",
            "ResNet50: 578.4158706665039\n",
            "VGG16: 616.7998313903809\n"
          ]
        }
      ],
      "source": [
        "# Task A: Model Selection\n",
        "# Step 1: 安裝所需的 pytorch 和 torchvision 套件\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Step 2: 導入所需的庫\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from time import time\n",
        "\n",
        "# Step 3: 選擇兩個預訓練模型\n",
        "# 這裡選擇了 ResNet50 和 VGG16 作為遷移學習的模型\n",
        "model1_name = \"ResNet50\"\n",
        "model2_name = \"VGG16\"\n",
        "model1 = models.resnet50(pretrained=True)\n",
        "model2 = models.vgg16(pretrained=True)\n",
        "\n",
        "# 顯示模型架構\n",
        "print(f\"{model1_name} 架構:\\n\", model1)\n",
        "print(f\"\\n{model2_name} 架構:\\n\", model2)\n",
        "\n",
        "# Step 4: 模型選擇理由\n",
        "model_choices = {\n",
        "    model1_name: {\n",
        "        \"architecture\": \"ResNet50 使用殘差塊結構，適合處理更深的網路，並可以降低梯度消失的風險。\",\n",
        "        \"pretrained_performance\": \"在 ImageNet 上有高準確度，適合複雜的特徵提取。\",\n",
        "        \"transfer_learning_potential\": \"因為架構較深且適應性強，適合遷移學習中的細微分類任務。\"\n",
        "    },\n",
        "    model2_name: {\n",
        "        \"architecture\": \"VGG16 使用多層卷積層，結構相對簡單，易於理解和修改。\",\n",
        "        \"pretrained_performance\": \"在 ImageNet 上也具備良好準確度，尤其在圖片分類方面。\",\n",
        "        \"transfer_learning_potential\": \"穩定適用於遷移學習，適合計算時間較短的任務，但可能需要調整層數以適應新任務。\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# 顯示模型選擇理由\n",
        "for model_name, info in model_choices.items():\n",
        "    print(f\"\\n{model_name} 選擇理由：\")\n",
        "    for key, value in info.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Step 5: 測試推理時間\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_tensor = torch.rand(1, 3, 224, 224).to(device)  # 隨機生成一個測試圖像\n",
        "\n",
        "def measure_time(model, input_tensor):\n",
        "    model = model.to(device)  # 將模型轉移到 GPU（如果可用）\n",
        "    model.eval()  # 設置模型為評估模式\n",
        "    with torch.no_grad():\n",
        "        # 測量推理時間\n",
        "        start_time = time()\n",
        "        model(input_tensor)\n",
        "        end_time = time()\n",
        "        return (end_time - start_time) * 1000  # 轉換為毫秒\n",
        "\n",
        "# 測量兩個模型的推理時間\n",
        "print(\"\\n推理時間測試（毫秒）：\")\n",
        "print(f\"{model1_name}:\", measure_time(model1, input_tensor))\n",
        "print(f\"{model2_name}:\", measure_time(model2, input_tensor))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "08DK89cEDucU",
        "outputId": "e223d037-f44b-4729-ebaa-e1aff319511e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "微調 ResNet50...\n",
            "Epoch [1/5], Loss: 0.7468\n",
            "Epoch [2/5], Loss: 0.7081\n",
            "Epoch [3/5], Loss: 0.7308\n",
            "Epoch [4/5], Loss: 0.7029\n",
            "Epoch [5/5], Loss: 0.6972\n",
            "\n",
            "微調 VGG16...\n",
            "Epoch [1/5], Loss: 1.5614\n",
            "Epoch [2/5], Loss: 0.7147\n",
            "Epoch [3/5], Loss: 0.7011\n",
            "Epoch [4/5], Loss: 0.6972\n",
            "Epoch [5/5], Loss: 0.7078\n",
            "\n",
            "性能評估:\n",
            "ResNet50 測試集準確率: 0.5450\n",
            "VGG16 測試集準確率: 0.4600\n"
          ]
        }
      ],
      "source": [
        "# Task B: Fine-tuning the ConvNet\n",
        "# Step 1: 安裝所需的套件\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Step 2: 導入所需的庫\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 3: 資料預處理與資料集加載\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 使用 FakeData 模擬二分類 X 光資料集（以 1000 張訓練圖像和 200 張測試圖像為例）\n",
        "train_dataset = datasets.FakeData(size=1000, transform=transform, num_classes=2)\n",
        "test_dataset = datasets.FakeData(size=200, transform=transform, num_classes=2)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 4: 模型選擇與微調設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 選擇 ResNet50 和 VGG16 並修改最後一層以適應二分類\n",
        "model1 = models.resnet50(pretrained=True)\n",
        "model1.fc = nn.Linear(model1.fc.in_features, 2)  # 修改 ResNet50 的全連接層\n",
        "model1 = model1.to(device)\n",
        "\n",
        "model2 = models.vgg16(pretrained=True)\n",
        "model2.classifier[6] = nn.Linear(model2.classifier[6].in_features, 2)  # 修改 VGG16 的全連接層\n",
        "model2 = model2.to(device)\n",
        "\n",
        "# 定義損失函數和優化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "# Step 5: 訓練與微調函數\n",
        "def train_model(model, optimizer, train_loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# 微調 ResNet50\n",
        "print(\"微調 ResNet50...\")\n",
        "train_model(model1, optimizer1, train_loader)\n",
        "\n",
        "# 微調 VGG16\n",
        "print(\"\\n微調 VGG16...\")\n",
        "train_model(model2, optimizer2, train_loader)\n",
        "\n",
        "# Step 6: 性能評估函數\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# 評估微調後的模型\n",
        "print(\"\\n性能評估:\")\n",
        "resnet50_accuracy = evaluate_model(model1, test_loader)\n",
        "vgg16_accuracy = evaluate_model(model2, test_loader)\n",
        "print(f\"ResNet50 測試集準確率: {resnet50_accuracy:.4f}\")\n",
        "print(f\"VGG16 測試集準確率: {vgg16_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task C: ConvNet as Fixed Feature Extractor\n",
        "# Step 1: 安裝所需的套件\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Step 2: 導入所需的庫\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 3: 資料預處理與資料集加載\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 使用 FakeData 模擬二分類 X 光資料集（以 1000 張訓練圖像和 200 張測試圖像為例）\n",
        "train_dataset = datasets.FakeData(size=1000, transform=transform, num_classes=2)\n",
        "test_dataset = datasets.FakeData(size=200, transform=transform, num_classes=2)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 4: 模型選擇與固定特徵提取器設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 選擇 ResNet50 和 VGG16 並凍結所有層（僅訓練最後一層）\n",
        "model1 = models.resnet50(pretrained=True)\n",
        "for param in model1.parameters():\n",
        "    param.requires_grad = False\n",
        "model1.fc = nn.Linear(model1.fc.in_features, 2)  # 修改最後一層\n",
        "model1 = model1.to(device)\n",
        "\n",
        "model2 = models.vgg16(pretrained=True)\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "model2.classifier[6] = nn.Linear(model2.classifier[6].in_features, 2)  # 修改最後一層\n",
        "model2 = model2.to(device)\n",
        "\n",
        "# 定義損失函數和優化器（只優化最後一層）\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model1.fc.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(model2.classifier[6].parameters(), lr=0.001)\n",
        "\n",
        "# Step 5: 訓練函數\n",
        "def train_model_fixed_extractor(model, optimizer, train_loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# 訓練 ResNet50 作為固定特徵提取器\n",
        "print(\"ResNet50 固定特徵提取器模式訓練...\")\n",
        "train_model_fixed_extractor(model1, optimizer1, train_loader)\n",
        "\n",
        "# 訓練 VGG16 作為固定特徵提取器\n",
        "print(\"\\nVGG16 固定特徵提取器模式訓練...\")\n",
        "train_model_fixed_extractor(model2, optimizer2, train_loader)\n",
        "\n",
        "# Step 6: 性能評估函數\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# 評估作為固定特徵提取器的模型性能\n",
        "print(\"\\n性能評估:\")\n",
        "resnet50_accuracy = evaluate_model(model1, test_loader)\n",
        "vgg16_accuracy = evaluate_model(model2, test_loader)\n",
        "print(f\"ResNet50 測試集準確率: {resnet50_accuracy:.4f}\")\n",
        "print(f\"VGG16 測試集準確率: {vgg16_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMuZYcNrLlyd",
        "outputId": "b9ad3892-1a22-4e23-8151-fbad5df79e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50 固定特徵提取器模式訓練...\n",
            "Epoch [1/5], Loss: 0.7388\n",
            "Epoch [2/5], Loss: 0.7052\n",
            "Epoch [3/5], Loss: 0.6719\n",
            "Epoch [4/5], Loss: 0.6569\n",
            "Epoch [5/5], Loss: 0.6350\n",
            "\n",
            "VGG16 固定特徵提取器模式訓練...\n",
            "Epoch [1/5], Loss: 0.7757\n",
            "Epoch [2/5], Loss: 0.7414\n",
            "Epoch [3/5], Loss: 0.7162\n",
            "Epoch [4/5], Loss: 0.7440\n",
            "Epoch [5/5], Loss: 0.7481\n",
            "\n",
            "性能評估:\n",
            "ResNet50 測試集準確率: 0.5000\n",
            "VGG16 測試集準確率: 0.5400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task D: Comparison and Analysis\n",
        "# Step 1: 安裝所需的套件\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Step 2: 導入所需的庫\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 3: 資料預處理與資料集加載\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 使用 FakeData 模擬二分類 X 光資料集（以 1000 張訓練圖像和 200 張測試圖像為例）\n",
        "train_dataset = datasets.FakeData(size=1000, transform=transform, num_classes=2)\n",
        "test_dataset = datasets.FakeData(size=200, transform=transform, num_classes=2)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 4: 定義模型訓練和評估函數\n",
        "def train_model(model, optimizer, train_loader, epochs=5):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# Step 5: 微調模式下訓練和評估\n",
        "def finetune_model():\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"\\n微調 ResNet50 模型訓練:\")\n",
        "    train_model(model, optimizer, train_loader)\n",
        "    accuracy = evaluate_model(model, test_loader)\n",
        "    print(f\"微調模式 ResNet50 測試集準確率: {accuracy:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Step 6: 固定特徵提取模式下訓練和評估\n",
        "def feature_extractor_model():\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"\\n固定特徵提取 ResNet50 模型訓練:\")\n",
        "    train_model(model, optimizer, train_loader)\n",
        "    accuracy = evaluate_model(model, test_loader)\n",
        "    print(f\"固定特徵提取模式 ResNet50 測試集準確率: {accuracy:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Step 7: 比較與分析\n",
        "print(\"開始進行微調與固定特徵提取模型的比較:\")\n",
        "finetune_accuracy = finetune_model()\n",
        "feature_extractor_accuracy = feature_extractor_model()\n",
        "\n",
        "print(\"\\n模型比較與分析結果:\")\n",
        "print(f\"微調模式下 ResNet50 測試集準確率: {finetune_accuracy:.4f}\")\n",
        "print(f\"固定特徵提取模式下 ResNet50 測試集準確率: {feature_extractor_accuracy:.4f}\")\n",
        "\n",
        "# 簡要分析\n",
        "if finetune_accuracy > feature_extractor_accuracy:\n",
        "    print(\"微調模式的性能更佳，說明模型在允許所有層進行更新時，能更好地適應新任務的細微特徵。\")\n",
        "else:\n",
        "    print(\"固定特徵提取模式的性能更佳，顯示出預訓練特徵在此二分類任務上已經相當適合，不需要額外的微調。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Top3ER7Ucpz_",
        "outputId": "dec4629e-7916-40bc-8bfd-40e80f75497d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "開始進行微調與固定特徵提取模型的比較:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "微調 ResNet50 模型訓練:\n",
            "Epoch [1/5], Loss: 0.7954\n",
            "Epoch [2/5], Loss: 0.6922\n",
            "Epoch [3/5], Loss: 0.6123\n",
            "Epoch [4/5], Loss: 0.4028\n",
            "Epoch [5/5], Loss: 0.2963\n",
            "微調模式 ResNet50 測試集準確率: 0.9300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "固定特徵提取 ResNet50 模型訓練:\n",
            "Epoch [1/5], Loss: 0.7516\n",
            "Epoch [2/5], Loss: 0.6968\n",
            "Epoch [3/5], Loss: 0.6762\n",
            "Epoch [4/5], Loss: 0.6933\n",
            "Epoch [5/5], Loss: 0.6634\n",
            "固定特徵提取模式 ResNet50 測試集準確率: 0.5550\n",
            "\n",
            "模型比較與分析結果:\n",
            "微調模式下 ResNet50 測試集準確率: 0.9300\n",
            "固定特徵提取模式下 ResNet50 測試集準確率: 0.5550\n",
            "微調模式的性能更佳，說明模型在允許所有層進行更新時，能更好地適應新任務的細微特徵。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task E: Test Dataset Analysis\n",
        "# Step 1: 安裝所需的套件\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Step 2: 導入所需的庫\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Step 3: 資料預處理與資料集加載\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 使用 FakeData 模擬二分類 X 光資料集（以 1000 張訓練圖像和 200 張測試圖像為例）\n",
        "train_dataset = datasets.FakeData(size=1000, transform=transform, num_classes=2)\n",
        "test_dataset = datasets.FakeData(size=200, transform=transform, num_classes=2)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 4: 定義 ResNet50 模型，並僅調整最後一層以適應二分類任務\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # 修改最後一層輸出為二分類\n",
        "model = model.to(device)\n",
        "\n",
        "# 定義損失函數和優化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 5: 訓練函數\n",
        "def train_model(model, optimizer, train_loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Step 6: 評估函數\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# Step 7: 模型訓練與性能測試\n",
        "print(\"模型訓練...\")\n",
        "train_model(model, optimizer, train_loader)\n",
        "\n",
        "print(\"\\n性能評估:\")\n",
        "train_accuracy = evaluate_model(model, train_loader)\n",
        "test_accuracy = evaluate_model(model, test_loader)\n",
        "print(f\"訓練集準確率: {train_accuracy:.4f}\")\n",
        "print(f\"測試集準確率: {test_accuracy:.4f}\")\n",
        "\n",
        "# Step 8: 分析測試資料集性能限制的原因\n",
        "print(\"\\n性能分析與討論:\")\n",
        "if test_accuracy < train_accuracy:\n",
        "    print(\"在此實驗中，測試集性能低於訓練集，這可能是由以下幾個原因引起的：\\n\")\n",
        "    print(\"1. 過擬合：模型在訓練集上過度學習，對訓練資料的特徵進行過度擬合，導致在測試集上泛化效果較差。\")\n",
        "    print(\"2. 測試資料集的分布與訓練資料集存在差異：即使 FakeData 模擬資料隨機生成，但在實際應用中，測試集可能包含不同分布或新特徵，導致模型無法正確分類。\")\n",
        "    print(\"3. 資料集大小限制：測試集樣本數較少，可能不足以代表真實的數據分布，導致性能測試時波動較大。\")\n",
        "    print(\"4. 模型架構限制：即便使用 ResNet50 等強大模型，當數據特徵複雜或需要特別處理時（例如 X 光影像中特徵差異不明顯），模型仍可能無法正確分類。\")\n",
        "else:\n",
        "    print(\"測試集和訓練集的性能相當，模型具有良好的泛化性，但依然可能因資料集分布的細微差異而有所提升空間。\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xar8tq-uvj5E",
        "outputId": "ab7de240-32e6-4282-a412-a8b471bc94dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型訓練...\n",
            "Epoch [1/5], Loss: 0.7576\n",
            "Epoch [2/5], Loss: 0.6867\n",
            "Epoch [3/5], Loss: 0.6751\n",
            "Epoch [4/5], Loss: 0.4793\n",
            "Epoch [5/5], Loss: 0.3751\n",
            "\n",
            "性能評估:\n",
            "訓練集準確率: 0.8550\n",
            "測試集準確率: 0.8500\n",
            "\n",
            "性能分析與討論:\n",
            "在此實驗中，測試集性能低於訓練集，這可能是由以下幾個原因引起的：\n",
            "\n",
            "1. 過擬合：模型在訓練集上過度學習，對訓練資料的特徵進行過度擬合，導致在測試集上泛化效果較差。\n",
            "2. 測試資料集的分布與訓練資料集存在差異：即使 FakeData 模擬資料隨機生成，但在實際應用中，測試集可能包含不同分布或新特徵，導致模型無法正確分類。\n",
            "3. 資料集大小限制：測試集樣本數較少，可能不足以代表真實的數據分布，導致性能測試時波動較大。\n",
            "4. 模型架構限制：即便使用 ResNet50 等強大模型，當數據特徵複雜或需要特別處理時（例如 X 光影像中特徵差異不明顯），模型仍可能無法正確分類。\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpaeCSibeQbClbe1Tnt3GJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}